{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "048ea33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yehan Perera\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ydata_profiling import ProfileReport\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from wordcloud import WordCloud\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from warnings import filterwarnings\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score, silhouette_samples\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "from factor_analyzer import FactorAnalyzer\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from itertools import combinations\n",
    "from kmodes.kprototypes import KPrototypes\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "### so that u dont have warnings\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50ca548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"zomato.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc54e2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_initial(data):\n",
    "    ### Remove unwanted columns \n",
    "    col_to_remove = ['url','address','phone','reviews_list','menu_item']\n",
    "    df = data.drop(columns=col_to_remove)\n",
    "    \n",
    "    # remove duplicates\n",
    "    df.drop_duplicates(inplace=True)\n",
    "    \n",
    "\n",
    "    def fun(x):\n",
    "        x_new = x.split(',')\n",
    "        return x_new[0]+x_new[1]\n",
    "    df['approx_cost(for two people)']=df['approx_cost(for two people)'].apply(lambda x: fun(x) if ',' in str(x) else x)\n",
    "    df['approx_cost(for two people)'] = pd.to_numeric(df['approx_cost(for two people)'])\n",
    "    \n",
    "    \n",
    "    # rate \n",
    "    df['rate'] = df['rate'].apply(lambda x : str(x).split('/')[0])\n",
    "    ls = [float(i) for i in df['rate'] if (i!='NEW') & (i!='nan') & (i!='-')]\n",
    "    mean_rate = round(np.mean(ls),1)\n",
    "    df['rate'] = df['rate'].apply(lambda x: mean_rate if (x=='NEW') | (x=='-') | (x=='nan') else x)\n",
    "    df['rate'] = pd.to_numeric(df['rate'])\n",
    "    ## Remove the missing values of response \n",
    "    df.dropna(subset=['approx_cost(for two people)'], inplace=True)\n",
    "    \n",
    "     #########   categorical variables \n",
    "    vars_to_impute = ['location','rest_type','dish_liked','cuisines']\n",
    "    for col in vars_to_impute:\n",
    "        df.dropna(subset=[col],inplace=True)\n",
    "        \n",
    "        \n",
    "    ## Split the data \n",
    "    X= df.drop(columns=['approx_cost(for two people)'])\n",
    "    Y = df['approx_cost(for two people)']\n",
    "   \n",
    "    return   X ,Y \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0adb8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X , Y = preprocessing_initial(df_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "611c8ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders import TargetEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3e97451",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n",
      "Warning: No categorical columns found. Calling 'transform' will only return input data.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Define your target encoder columns\n",
    "target_encoder_cols = ['name', 'dish_liked', 'cuisines', 'location', 'rest_type', 'listed_in(city)', 'listed_in(type)', 'online_order', 'book_table']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform frequency encoding for each column\n",
    "for col in target_encoder_cols:\n",
    "    target_encoder = TargetEncoder()\n",
    "\n",
    "    # Fit and transform the target encoder on the training data\n",
    "    X_train[target_encoder_cols] = target_encoder.fit_transform(X_train[target_encoder_cols], y_train)\n",
    "\n",
    "    # Transform the test data using the target encoder fitted on the training data\n",
    "    X_test[target_encoder_cols] = target_encoder.transform(X_test[target_encoder_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a59e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd15178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "random_seed = 42\n",
    "clf = IsolationForest(contamination=0.2, random_state=random_seed)\n",
    "clf.fit(X_train)\n",
    "predictions = clf.predict(X_train)\n",
    "\n",
    "X_train['cluster_label'] = predictions\n",
    "\n",
    "X_train_1 = X_train[X_train['cluster_label']== -1]\n",
    "X_train_2 = X_train[X_train['cluster_label']== 1]\n",
    "\n",
    "indexes_1 = X_train_1.index\n",
    "indexes_2 = X_train_2.index\n",
    "\n",
    "\n",
    "y_train_1 = y_train.loc[indexes_1]\n",
    "y_train_2 = y_train.loc[indexes_2]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc771aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ab21c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6737da58",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cluster_1 , x_test_cluster_1 , y_train_cluster_1 , y_test_cluster_1 = train_test_split(X_train_1,y_train_1,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "508cecbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (RandomForest): Index(['name', 'rest_type', 'dish_liked'], dtype='object')\n",
      "Mean Absolute Percentage Error on Training set (RandomForest): 0.6968742631637074\n",
      "Mean Absolute Percentage Error on Testing set (RandomForest): 1.8139797025002327\n",
      "Best Hyperparameters (RandomForest): {'rf__max_depth': 20, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "\n",
    "# Create Pipeline with feature selection and RandomForest\n",
    "pipeline_rf = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(RandomForestRegressor())),\n",
    "    ('rf', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning for RandomForest\n",
    "rf_params = {\n",
    "    'rf__n_estimators': [50, 100, 200, 300],\n",
    "    'rf__max_depth': [None, 5, 10, 20],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Assuming x_train_cluster_1, y_train_cluster_1, x_test_cluster_1, y_test_cluster_1 are defined\n",
    "\n",
    "# Perform GridSearchCV for RandomForest\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, rf_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV for RandomForest\n",
    "grid_search_rf.fit(x_train_cluster_1, y_train_cluster_1)\n",
    "\n",
    "# Get the best model for RandomForest\n",
    "best_model_rf_1 = grid_search_rf.best_estimator_\n",
    "\n",
    "# Get the selected features for RandomForest\n",
    "selected_features_rf = x_train_cluster_1.columns[best_model_rf_1.named_steps['feature_selection'].get_support()]\n",
    "\n",
    "# Evaluate the best model for RandomForest\n",
    "mape_train_rf = np.mean(np.abs((y_train_cluster_1 - best_model_rf_1.predict(x_train_cluster_1)) / y_train_cluster_1)) * 100\n",
    "mape_test_rf = np.mean(np.abs((y_test_cluster_1 - best_model_rf_1.predict(x_test_cluster_1)) / y_test_cluster_1)) * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Selected Features (RandomForest):\", selected_features_rf)\n",
    "print(\"Mean Absolute Percentage Error on Training set (RandomForest):\", mape_train_rf)\n",
    "print(\"Mean Absolute Percentage Error on Testing set (RandomForest):\", mape_test_rf)\n",
    "print(\"Best Hyperparameters (RandomForest):\", grid_search_rf.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58782ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Random Forest) for Cluster 1: Index(['name', 'rest_type', 'dish_liked'], dtype='object')\n",
      "Mean Absolute Percentage Error on Training set (Random Forest) for Cluster 1: 0.6968742631637074\n",
      "Mean Absolute Percentage Error on Testing set (Random Forest) for Cluster 1: 1.8139797025002327\n",
      "Root Mean Squared Error on Training set (Random Forest) for Cluster 1: 31.141131460264415\n",
      "Root Mean Squared Error on Testing set (Random Forest) for Cluster 1: 85.9426994668197\n",
      "{'rf__max_depth': 20, 'rf__max_features': 'log2', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Predictions for Cluster 1 using Random Forest\n",
    "y_train_pred_rf_cluster_1 = best_model_rf_1.predict(x_train_cluster_1)\n",
    "y_test_pred_rf_cluster_1 = best_model_rf_1.predict(x_test_cluster_1)\n",
    "\n",
    "# Calculate RMSE for Cluster 1 using Random Forest\n",
    "rmse_train_rf_cluster_1 = np.sqrt(mean_squared_error(y_train_cluster_1, y_train_pred_rf_cluster_1))\n",
    "rmse_test_rf_cluster_1 = np.sqrt(mean_squared_error(y_test_cluster_1, y_test_pred_rf_cluster_1))\n",
    "\n",
    "# Mean Absolute Percentage Error for Cluster 1 using Random Forest\n",
    "mape_train_rf_cluster_1 = np.mean(np.abs((y_train_cluster_1 - y_train_pred_rf_cluster_1) / y_train_cluster_1)) * 100\n",
    "mape_test_rf_cluster_1 = np.mean(np.abs((y_test_cluster_1 - y_test_pred_rf_cluster_1) / y_test_cluster_1)) * 100\n",
    "\n",
    "print(\"Selected Features (Random Forest) for Cluster 1:\", selected_features_rf)\n",
    "print(\"Mean Absolute Percentage Error on Training set (Random Forest) for Cluster 1:\", mape_train_rf_cluster_1)\n",
    "print(\"Mean Absolute Percentage Error on Testing set (Random Forest) for Cluster 1:\", mape_test_rf_cluster_1)\n",
    "print(\"Root Mean Squared Error on Training set (Random Forest) for Cluster 1:\", rmse_train_rf_cluster_1)\n",
    "print(\"Root Mean Squared Error on Testing set (Random Forest) for Cluster 1:\", rmse_test_rf_cluster_1)\n",
    "print(grid_search_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d86d27a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0032e3ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "799e5360",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cluster_2 , x_test_cluster_2 , y_train_cluster_2 , y_test_cluster_2 = train_test_split(X_train_2,\n",
    "                                                                                    y_train_2,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f47d2a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (RandomForest): Index(['name', 'dish_liked'], dtype='object')\n",
      "Mean Absolute Percentage Error on Training set (RandomForest): 0.6908083009801965\n",
      "Mean Absolute Percentage Error on Testing set (RandomForest): 1.4624562257849252\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "\n",
    "# Create Pipeline with feature selection and RandomForest\n",
    "pipeline_rf = Pipeline([\n",
    "    ('feature_selection', SelectFromModel(RandomForestRegressor())),\n",
    "    ('rf', RandomForestRegressor())\n",
    "])\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning for RandomForest\n",
    "rf_params = {\n",
    "    'rf__n_estimators': [50, 100, 200, 300],\n",
    "    'rf__max_depth': [None, 5, 10, 20],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for RandomForest\n",
    "grid_search_rf = GridSearchCV(pipeline_rf, rf_params, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV for RandomForest\n",
    "grid_search_rf.fit(x_train_cluster_2, y_train_cluster_2)\n",
    "\n",
    "# Get the best model for RandomForest\n",
    "best_model_rf_2 = grid_search_rf.best_estimator_\n",
    "\n",
    "# Get the selected features for RandomForest\n",
    "selected_features_rf = x_train_cluster_2.columns[best_model_rf_2.named_steps['feature_selection'].get_support()]\n",
    "\n",
    "# Evaluate the best model for RandomForest\n",
    "mape_train_rf = np.mean(np.abs((y_train_cluster_2 - best_model_rf_2.predict(x_train_cluster_2)) / y_train_cluster_2)) * 100\n",
    "mape_test_rf = np.mean(np.abs((y_test_cluster_2 - best_model_rf_2.predict(x_test_cluster_2)) / y_test_cluster_2)) * 100\n",
    "\n",
    "print(\"Selected Features (RandomForest):\", selected_features_rf)\n",
    "print(\"Mean Absolute Percentage Error on Training set (RandomForest):\", mape_train_rf)\n",
    "print(\"Mean Absolute Percentage Error on Testing set (RandomForest):\", mape_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0229351b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Random Forest) for Cluster 2: Index(['name', 'dish_liked'], dtype='object')\n",
      "Mean Absolute Percentage Error on Training set (Random Forest) for Cluster 2: 0.6908083009801965\n",
      "Mean Absolute Percentage Error on Testing set (Random Forest) for Cluster 2: 1.4624562257849252\n",
      "Root Mean Squared Error on Training set (Random Forest) for Cluster 2: 14.955298918984171\n",
      "Root Mean Squared Error on Testing set (Random Forest) for Cluster 2: 34.976263868466035\n",
      "{'rf__max_depth': None, 'rf__max_features': 'sqrt', 'rf__min_samples_leaf': 1, 'rf__min_samples_split': 2, 'rf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "# Predictions for Cluster 2 using Random Forest\n",
    "y_train_pred_rf_cluster_2 = best_model_rf_2.predict(x_train_cluster_2)\n",
    "y_test_pred_rf_cluster_2 = best_model_rf_2.predict(x_test_cluster_2)\n",
    "\n",
    "# Calculate RMSE for Cluster 2 using Random Forest\n",
    "rmse_train_rf_cluster_2 = np.sqrt(mean_squared_error(y_train_cluster_2, y_train_pred_rf_cluster_2))\n",
    "rmse_test_rf_cluster_2 = np.sqrt(mean_squared_error(y_test_cluster_2, y_test_pred_rf_cluster_2))\n",
    "\n",
    "# Mean Absolute Percentage Error for Cluster 2 using Random Forest\n",
    "mape_train_rf_cluster_2 = np.mean(np.abs((y_train_cluster_2 - y_train_pred_rf_cluster_2) / y_train_cluster_2)) * 100\n",
    "mape_test_rf_cluster_2 = np.mean(np.abs((y_test_cluster_2 - y_test_pred_rf_cluster_2) / y_test_cluster_2)) * 100\n",
    "\n",
    "print(\"Selected Features (Random Forest) for Cluster 2:\", selected_features_rf)\n",
    "print(\"Mean Absolute Percentage Error on Training set (Random Forest) for Cluster 2:\", mape_train_rf_cluster_2)\n",
    "print(\"Mean Absolute Percentage Error on Testing set (Random Forest) for Cluster 2:\", mape_test_rf_cluster_2)\n",
    "print(\"Root Mean Squared Error on Training set (Random Forest) for Cluster 2:\", rmse_train_rf_cluster_2)\n",
    "print(\"Root Mean Squared Error on Testing set (Random Forest) for Cluster 2:\", rmse_test_rf_cluster_2)\n",
    "print(grid_search_rf.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a25e0e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'dish_liked'], dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d17534b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cf4eb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf188684",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb83470",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f676c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "127e5c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error for Cluster 1: 4.683200107291389\n",
      "Mean Absolute Percentage Error for Cluster 2: 7.50545874908213\n"
     ]
    }
   ],
   "source": [
    "new_preds = clf.predict(X_test)\n",
    "\n",
    "# Define best models for each cluster\n",
    "best_model_cluster_1 =best_model_rf_1\n",
    "best_model_cluster_2 = best_model_rf_2\n",
    "\n",
    "# Assign cluster labels to X_test\n",
    "X_test['cluster_label'] = new_preds\n",
    "\n",
    "# Filter X_test for each cluster\n",
    "X_test_1 = X_test[X_test['cluster_label'] == -1]\n",
    "X_test_2 = X_test[X_test['cluster_label'] == 1]\n",
    "\n",
    "# Get the indexes for each cluster\n",
    "indexes_1 = X_test_1.index\n",
    "indexes_2 = X_test_2.index\n",
    "\n",
    "# Filter y_test for each cluster\n",
    "y_test_1 = y_test.loc[indexes_1]\n",
    "y_test_2 = y_test.loc[indexes_2]\n",
    "\n",
    "# Predictions for each cluster using the corresponding best model\n",
    "y_test_pred_cluster_1 = best_model_cluster_1.predict(X_test_1)\n",
    "y_test_pred_cluster_2 = best_model_cluster_2.predict(X_test_2)\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE) for cluster 1\n",
    "mape_cluster_1 = np.mean(np.abs((y_test_1 - y_test_pred_cluster_1) / y_test_1)) * 100\n",
    "\n",
    "# Calculate Mean Absolute Percentage Error (MAPE) for cluster 2\n",
    "mape_cluster_2 = np.mean(np.abs((y_test_2 - y_test_pred_cluster_2) / y_test_2)) * 100\n",
    "\n",
    "# Print MAPE for each cluster\n",
    "print(\"Mean Absolute Percentage Error for Cluster 1:\", mape_cluster_1)\n",
    "print(\"Mean Absolute Percentage Error for Cluster 2:\", mape_cluster_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4d3efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f5fe5ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Cluster 1: 43366.703369468276\n",
      "Root Mean Squared Error for Cluster 1: 208.2467367558692\n",
      "Mean Squared Error for Cluster 2: 9772.36851354447\n",
      "Root Mean Squared Error for Cluster 2: 98.85529077163483\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for cluster 1\n",
    "mse_cluster_1 = mean_squared_error(y_test_1, y_test_pred_cluster_1)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) for cluster 2\n",
    "mse_cluster_2 = mean_squared_error(y_test_2, y_test_pred_cluster_2)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for cluster 1\n",
    "rmse_cluster_1 = math.sqrt(mse_cluster_1)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for cluster 2\n",
    "rmse_cluster_2 = math.sqrt(mse_cluster_2)\n",
    "\n",
    "# Print MSE and RMSE for each cluster\n",
    "print(\"Mean Squared Error for Cluster 1:\", mse_cluster_1)\n",
    "print(\"Root Mean Squared Error for Cluster 1:\", rmse_cluster_1)\n",
    "print(\"Mean Squared Error for Cluster 2:\", mse_cluster_2)\n",
    "print(\"Root Mean Squared Error for Cluster 2:\", rmse_cluster_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6cecd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c8bec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Percentage Error for Combined Predictions: 6.988537258162133\n"
     ]
    }
   ],
   "source": [
    "# Combine predictions and actual values for both clusters\n",
    "y_test_combined = pd.concat([y_test_1, y_test_2], axis=0)\n",
    "\n",
    "# Combine predictions for both clusters\n",
    "y_pred_combined = np.concatenate([y_test_pred_cluster_1, y_test_pred_cluster_2])\n",
    "\n",
    "# Calculate MAPE for combined predictions\n",
    "mape_combined = np.mean(np.abs((y_test_combined - y_pred_combined) / y_test_combined)) * 100\n",
    "\n",
    "# Print MAPE for combined predictions\n",
    "print(\"Mean Absolute Percentage Error for Combined Predictions:\", mape_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05645174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "104ad96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error for Combined Predictions: 15925.466391622414\n",
      "Root Mean Squared Error for Combined Predictions: 126.19614253859908\n"
     ]
    }
   ],
   "source": [
    "# Calculate Mean Squared Error (MSE) for combined predictions\n",
    "mse_combined = mean_squared_error(y_test_combined, y_pred_combined)\n",
    "\n",
    "# Calculate Root Mean Squared Error (RMSE) for combined predictions\n",
    "rmse_combined = math.sqrt(mse_combined)\n",
    "\n",
    "# Print MSE and RMSE for combined predictions\n",
    "print(\"Mean Squared Error for Combined Predictions:\", mse_combined)\n",
    "print(\"Root Mean Squared Error for Combined Predictions:\", rmse_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b437001f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144de331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086389c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a38240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2d3bb9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26440b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30097093",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d10c3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea22ea4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd230c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad817397",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a6fa19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2497bf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2446ab50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
